{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    # turns string into list of strings separated by spaces\n",
    "    return s.split()\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        string s\n",
    "    Output:\n",
    "        list of strings\n",
    "    \"\"\"\n",
    "    \n",
    "def preprocess(s, lowercase=True, strip_punctuation=True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        string s\n",
    "        boolean lowercase\n",
    "        boolean strip_punctuation\n",
    "    Output:\n",
    "        list of strings\n",
    "    \"\"\"\n",
    "    punctuation='.,?<>:;\"\\'!%'\n",
    "    if isinstance(s, str):\n",
    "        # if s is an instance of the string class\n",
    "        s = tokenize(s)\n",
    "    if lowercase:\n",
    "        # if the lowercase option is true, go through each element in the list and turn the characters lowercase\n",
    "        s = [t.lower() for t in s]\n",
    "    if strip_punctuation:\n",
    "        # get rid of the punction for each of the elements in the list\n",
    "        # need to do this after splitting each word up because strip only looks at the beginning and end of a string\n",
    "        s = [t.strip(punctuation) for t in s]\n",
    "    return s\n",
    "    \n",
    "def token_frequency(tokens, tf=None, relative=False):\n",
    "    # We want to have raw frequency as default because if we want to look at multiple texts, then we can add the raw frequencies together\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        tokens = list of strings or None\n",
    "        tf = dict or None\n",
    "        realtive = boolean\n",
    "    Return:\n",
    "        dictionary of tokens and frequency {t:f}\n",
    "    \"\"\"\n",
    "    token_frequency = {} # dictionary to hold token counts\n",
    "    \n",
    "    # adding previous token frequency dictionary\n",
    "    token_frequency={} if tf==None else tf\n",
    "    if len(token_frequency) != 0 and relative==True:\n",
    "        if isinstance(list(token_frequency.items())[0][1], float):\n",
    "            print('warning, adding raw counts to relative frequency')\n",
    "            return tf\n",
    "    \n",
    "    # counting up the words\n",
    "    for token in tokens:\n",
    "        if token in token_frequency:\n",
    "            # if the token is already a key in the dictionary\n",
    "            token_frequency[token] += 1\n",
    "        else:\n",
    "            # token is not a key in the dictionary\n",
    "            token_frequency[token] = 1\n",
    "    \n",
    "    # changing to relative or keeping as raw frequency\n",
    "    if relative:\n",
    "        # relative frequency is wanted\n",
    "        total_words = sum([v for k, v in token_frequency.items()]) # total number of words in the string that was input and the new tf dictionary\n",
    "        return {k:v/total_words for k,v in token_frequency.items()} # go through each key, value pair in the dictionary and divide the value by the total number of words \n",
    "        # note: dictionary.items() turns the dictionary into a list of tuples ie. [(key1, value1), (key2, value2)]\n",
    "    else:\n",
    "        # want raw frequency\n",
    "        return token_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shaken', 'as', 'we', 'are,', 'so', 'wan', 'with', 'care,', 'Find']\n",
      "['be', 'the', 'heavens', 'with', 'black,', 'yield', 'day', 'to', 'night!']\n",
      "['your', 'ears;', 'for', 'which', 'of', 'you', 'will', 'stop', 'The']\n",
      "['by', 'your', 'high', 'imperial', 'majesty', 'I', 'had', 'in', 'charge']\n",
      "['wonder', 'how', 'the', 'king', 'escaped', 'our', 'hands.', 'While', 'we']\n",
      "['delivering', 'my', 'son', 'from', 'me,', 'I', 'bury', 'a', 'second']\n",
      "['but', 'this', 'dotage', 'of', 'our', \"general's\", \"O'erflows\", 'the', 'measure:']\n",
      "['I', 'remember,', 'Adam,', 'it', 'was', 'upon', 'this', 'fashion', 'bequeathed']\n",
      "['fair', 'Hippolyta,', 'our', 'nuptial', 'hour', 'Draws', 'on', 'apace;', 'four']\n",
      "['Solinus,', 'to', 'procure', 'my', 'fall', 'And', 'by', 'the', 'doom']\n",
      "['we', 'proceed', 'any', 'further,', 'hear', 'me', 'speak.', 'Speak,', 'speak.']\n",
      "['do', 'not', 'meet', 'a', 'man', 'but', 'frowns:', 'our', 'bloods']\n",
      "['there?', 'Nay,', 'answer', 'me:', 'stand,', 'and', 'unfold', 'yourself.', 'Long']\n",
      "['home,', 'you', 'idle', 'creatures', 'get', 'you', 'home:', 'Is', 'this']\n",
      "['for', 'a', 'Muse', 'of', 'fire,', 'that', 'would', 'ascend', 'The']\n",
      "['come', 'no', 'more', 'to', 'make', 'you', 'laugh:', 'things', 'now,']\n",
      "['say,', 'Chatillon,', 'what', 'would', 'France', 'with', 'us?', 'Thus,', 'after']\n",
      "['thought', 'the', 'king', 'had', 'more', 'affected', 'the', 'Duke', 'of']\n",
      "['John', 'of', 'Gaunt,', \"time-honour'd\", 'Lancaster,', 'Hast', 'thou,', 'according', 'to']\n",
      "['is', 'the', 'winter', 'of', 'our', 'discontent', 'Made', 'glorious', 'summer']\n",
      "['fame,', 'that', 'all', 'hunt', 'after', 'in', 'their', 'lives,', 'Live']\n",
      "['shall', 'we', 'three', 'meet', 'again', 'In', 'thunder,', 'lightning,', 'or']\n",
      "['My', 'lord.', 'Of', 'government', 'the', 'properties', 'to', 'unfold,', 'Would']\n",
      "['sooth,', 'I', 'know', 'not', 'why', 'I', 'am', 'so', 'sad:']\n",
      "['Hugh,', 'persuade', 'me', 'not;', 'I', 'will', 'make', 'a', 'Star-']\n",
      "['learn', 'in', 'this', 'letter', 'that', 'Don', 'Peter', 'of', 'Arragon']\n",
      "['never', 'tell', 'me;', 'I', 'take', 'it', 'much', 'unkindly', 'That']\n",
      "['households,', 'both', 'alike', 'in', 'dignity,', 'In', 'fair', 'Verona,', 'where']\n",
      "['pheeze', 'you,', 'in', 'faith.', 'A', 'pair', 'of', 'stocks,', 'you']\n",
      "['Here,', 'master:', 'what', 'cheer?', 'Good,', 'speak', 'to', 'the', 'mariners:']\n",
      "['day,', 'sir.', 'I', 'am', 'glad', \"you're\", 'well.', 'I', 'have']\n",
      "['patricians,', 'patrons', 'of', 'my', 'right,', 'Defend', 'the', 'justice', 'of']\n",
      "['Troy,', 'there', 'lies', 'the', 'scene.', 'From', 'isles', 'of', 'Greece']\n",
      "['music', 'be', 'the', 'food', 'of', 'love,', 'play', 'on;', 'Give']\n",
      "['to', 'persuade,', 'my', 'loving', 'Proteus:', 'Home-keeping', 'youth', 'have', 'ever']\n",
      "['you', 'shall', 'chance,', 'Camillo,', 'to', 'visit', 'Bohemia,', 'on', 'the']\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"./shakespeare/*.txt\")\n",
    "for file in files:\n",
    "    # tokenize text\n",
    "    text = open(file, \"r\").read()\n",
    "    tokens = tokenize(text)\n",
    "    print(token_frequency(tokens))\n",
    "    print(tokens[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
